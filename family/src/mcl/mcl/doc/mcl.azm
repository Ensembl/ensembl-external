\def{"man::synstyle"}{long}
\def{"man::defstyle"}{long}
\import{mcx.zmm}

\set{"man::name"}{mcl}
\set{"man::html-title"}{The mcl manual}
\set{"man::author"}{Stijn van Dongen}
\set{"man::section"}{1}
\set{"man::version"}{1.00}

\"man::preamble"
\${html}{\"man::maketoc"}

\sec{name}{NAME}
   \par
   mcl \- the Amsterdam implementation of the Markov Cluster Algorithm
      \${html}{(\bf{MCL algorithm})}

\sec{synopsis}{SYNOPSIS}
   \par
   \mcl <-|fname>
      \synoptopt{-I}{f}{inflation}
      \synoptopt{-o}{str}{fname}
      \|
      These two options are sufficient in 95 percent of the cases, or
      more.

   \par
   \mcl <-|fname>
      \synoptopt{-I}{f}{inflation}
      \synoptopt{-o}{str}{fname}
      \synoptopt{-c}{f}{centering}
      \synoptopt{-p}{f}{cutoff}
      \synoptopt{-P}{n}{1/cutoff}
      \synoptopt{-S}{n}{selection number}
      \synoptopt{-R}{n}{recovery number}
      \synoptopt{-pct}{f}{recover percentage}
      \synoptopt{-scheme}{k}{use preset scheme}
      \synoptopt{--show-schemes}{show preset schemes}
      \synoptopt{-warn-pct}{n}{prune warn percentage}
      \synoptopt{-warn-factor}{n}{prune warn factor}
      \synoptopt{--rigid}{pruning}
      \synoptopt{-ae}{f}{adaptive pruning exponent}
      \synoptopt{-af}{f}{adaptive pruning factor}
      \synoptopt{--adapt}{pruning}
      \synoptopt{-nx}{x}{track worst n}
      \synoptopt{-ny}{y}{track worst n}
      \synoptopt{-v}{str}{verbosity type on}
      \synoptopt{-V}{str}{verbosity type off}
      \synoptopt{--silent}{very}
      \synoptopt{--verbose}{very}
      \synoptopt{-progress}{k}{gauge}
      \synoptopt{-te}{k}{#expansion threads}
      \synoptopt{-ti}{k}{#inflation threads}
      \synoptopt{--clone}{when threading}
      \synoptopt{-cloneat}{n}{trigger}
      \synoptopt{-t}{k}{#threads}
      \synoptopt{-l}{n}{initial iteration number}
      \synoptopt{-L}{n}{main iteration number}
      \synoptopt{-i}{f}{initial inflation}
      \synoptopt{-a}{f}{loop weight}
      \synoptopt{-dumpi}{i:j}{interval i..j-1}
      \synoptopt{-dumpm}{k}{dump i+0..i+k..}
      \synoptopt{-dumpstem}{stem}{file stem}
      \synoptopt{-dump}{str}{type}
      \synoptopt{-digits}{n}{printing precision}
      \synoptopt{--show}{print matrices to screen}
      \synoptopt{--ascii}{output format}
      \synoptopt{--binary}{output format}
      \synoptopt{--overlap}{keep it}
      \synoptopt{--expand-only}{factor out computation}
      \synoptopt{--inflate-first}{rather then expand}
      \synoptopt{-preprune}{n}{input matrix}
      \synoptopt{-z}{show current settings}

\sec{description}{DESCRIPTION}

\par
   \mcl implements the \bf{MCL algorithm}, short for the \bf{Markov cluster
   algorithm}, a cluster algorithm for graphs developed by Stijn van Dongen at
   the Centre for Mathematics and Computer Science in Amsterdam, the
   Netherlands. The algorithm simulates flow using two simple algebraic
   operations on matrices. The theory behind it is extensively described
   elsewhere (see \secref{references}). The program described here is a fast
   threaded implementation written by the algorithm's creator with
   contributions by several others. Anton Enright co-implemented threading; see
   the \secref{history} section for a complete account.  The implementation is
   used for the TRIBES project in which large numbers of proteins are clustered
   into families, and has become all the better from the feedback this has
   generated.
   See the \secref{applicability} section for a description of the type of
   graph \mcl likes best, and for a qualitative assessment of its speed.

\par
   The \optref{-I}{\genopt{-I}{f} option} is the main control,
   affecting cluster granularity. Using \mcl is as simple as
   typing (assuming a file \it{proteins} contains a matrix/graph
   in \mcl input format)

\begin{vbt}
   mcl proteins -I 2.0
\end{vbt}

\par
   The above will result in a clustering written to the file
   named \it{out.mcl}. The \mcl input format is described in the
   \mcx5ref section. Clusterings are also stored as matrices
   - this is again discussed in the \mcx5ref section.
   In finding good \mcl parameter settings for a particular domain,
   or in finding cluster structure at different levels of granularity,
   one typically runs \mcl multiple times for varying values of f (refer
   to the \optref{-I}{\genopt{-I} option} for further information).


\par
   \mcl expects a nonnegative matrix in the input file, or equivalently, a
   weighted (possibly directed) graph.  NOTE \- \mcl interprets the matrix
   entries or graph edge weights as \bf{similarities}, and it likes
   \bf{undirected input graphs} best. It can handle directed graphs, but any
   node pair (i,j) for which w(i,j) is much smaller than w(j,i) or vice versa
   will presumably have a slightly negative effect on the clusterings output by
   \mcl. Many such node pairs will have a distinctly negative effect, so try to
   make your input graphs undirected.  How your edge weights are computed may
   affect \mcl's performance.  In protein clustering, it is best to choose the
   negated logarithm of the BLAST probabilities (see \secref{references}).


\par
   \mcl's default parameters should make it quite fast in almost all
   circumstances.  Taking default parameters, \mcl has been used to generate
   good protein clusters on 133k proteins, taking 10 minutes running time on a
   Compaq ES40 system with four alpha EV6.7 processors.

\par
   For large graphs, there are several groups of parameters available for
   tuning the mcl computing process, should it be necessary.
   The easiest thing
   to do is just vary the \optref{-scheme}{\genopt{-scheme} option}. This
   triggers different settings for the group of pruning parameters
   \optref{-P}{\bf{\{}\genopt{-p/-P}, \genopt{-R}, \genopt{-S}, and
   \genopt{-pct}\bf{\}}}.  The default setting corresponds with
   \useopt{-scheme}{2}.

   There is an additional group of control parameters
   \optref{--adapt}{\bf{\{}\genopt{--adapt}, \genopt{--rigid}, \genopt{-ae},
   \genopt{-af}\bf{\}}}, which may be helpful in speeding up \mcl.
   When doing multiple \mcl runs for the same graphs with different
   \genopt{-I} settings (for obtaining clusterings at different levels
   of granularity), it can be useful to factor out the first bit
   of computation that is common to all runs, by using
   the \optref{--expand-only}{\genopt{--expand-only} option} one time
   and then using \optref{--inflate-first}{\genopt{--inflate-first}} for
   each run in the set.

   Whether \mcl considers a graph large depends mainly on the graph
   connectivity; a highly connected graph on 50,000 nodes is large to
   \mcl (so that you might want to tune resources) whereas a sparsely
   connected graph on 500,000 nodes may be business as usual.  If graphs
   are really huge, the time to read a graph from file can be shortened
   by converting the input graph from ascii mcl format to binary mcl
   format with \sib{mcxconvert}.

   \par
   Two other groups of interest are the thread-related
   options (you can specify the number of threads to use)

   \optref{-t}{\bf{\{}\genopt{-t}, \genopt{-te}, \genopt{-ti}, 
   \genopt{--clone}, \genopt{-cloneat}\bf{\}}}

   and the verbosity-related options
   \optref{--verbose}{\bf{\{}\genopt{--verbose}, \genopt{--silent}, \genopt{-v}, 
   \genopt{-V}\bf{\}}}.

   The actual settings are shown with \genopt{-z}, and for graphs with
   at most 12 nodes or so you can view the MCL matrix iterands on screen
   by supplying \optref{--show}{\genopt{--show}} (this may give some
   more feeling).

\par
   The first option is the input file name (see the \mcx5ref section
   for its expected format), or a single hyphen to read from stdin.
   The rationale is that you typically do several runs with different
   parameters, and in command line mode it is pleasant if you do not have
   to skip over an immutable parameter all the time.

\par
   In the \secref{options} section options are listed in order of
   importance, with related options grouped together.

\par
   The creator of this page feels that manual pages are a valuable resource,
   that online html documentation is also a good thing to have, and
   that info pages are way \it{way} ahead of their time. The
   \secref{notes} section explains how this page was created.

\sec{options}{OPTIONS}

\begin{itemize}

   \itemnew
   \item{\defopt{-I}{f}{inflation}}
   \itemdef
      Sets the main inflation value to f. This value is the main handle
      for affecting cluster granularity. It is usually chosen somewhere
      in the range [1.2-5.0]. \useopt{-I}{5.0} will tend to result
      in fine-grained clusterings, and \useopt{-I}{1.2} will tend to
      result in very coarse grained clusterings. Your mileage will vary
      depending on the characteristics of your data.  That is why it is
      a good idea to test the quality and coherency of your clusterings
      using \sib{clmdist} and \sib{clminfo}.  This will most likely reveal that
      certain values of \genopt{-I} are simply not right for your data.  The
      \sib{clmdist} section contains a discussion of how to use the cluster
      validation tools shipped with \mcl (see the \secref{seealso} section).

      \par
      A second option for affecting cluster granularity is the
      \optref{-c}{\genopt{-c} option}.
      It may possibly increase granularity.

      \par
      With low values for \genopt{-I}, like \useopt{-I}{1.2}, you should be
      prepared to use more resources in order to maintain quality of
      clusterings, i.e. increase the arguments to the
      \optref{-P}{\genopt{-P/-S/-R} options} or simply increase
      the argument to \optref{-scheme}{\genopt{-scheme}}.
   \itemend

   \itemnew
   \item{\defopt{-o}{str}{fname}}
   \itemdef
      Output the clustering to file named fname. The default file name
      is out.mcl. It is possible to send the clustering to stdout
      by supplying \useopt{-o}{-}. The clustering is output in the
      mcl matrix format; see the \mcx5ref section for 
      more information on this.
   \itemend

   \itemnew
   \item{\defopt{-c}{f}{centering}}
   \itemdef
      The larger the value of f the more nodes are attached
      to themselves rather than their neighbours, the more
      expansion (the spreading of flow through the graph) is
      opposed, and the more fine-grained clusterings tend to be.  f should be
      chosen greater than or equal to 1.0.  The default is f=1.0.  This option
      has a much weaker effect than the \genopt{-I} option, but it can be
      useful depending on your data.
      
      \par
      The following resource control options are discussed as a group:
   \itemend

   \itemnew
   \item{\defopt{-p}{f}{cutoff}}
   \itemend

   \itemnew
   \item{\defopt{-P}{n}{1/cutoff}}
   \itemend

   \itemnew
   \item{\defopt{-S}{s}{selection number}}
   \itemend

   \itemnew
   \item{\defopt{-R}{r}{recover number}}
   \itemend

   \itemnew
   \item{\defopt{-pct}{pct}{recover percentage}}
   \itemend

   \itemnew
   \item{\defopt{-scheme}{k}{use a preset pruning scheme}}
   \itemend

   \itemnew
   \item{\defopt{--show-schemes}{show preset schemes}}
   \itemend

   \itemdef
      If you do not know nor want to know the mcl internals, just ignore the
      additional information below and follow the recommendations. They are
      quite straightforward.

      \par
      After computing a new (column stochastic) matrix vector during expansion
      (which is matrix multiplication c.q. squaring), the vector is
      successively exposed to different pruning strategies.  The intent of
      pruning is that many small entries are removed while retaining much of
      the stochastic mass of the original vector.  After pruning, vectors are
      rescaled to be stochastic again.  MCL iterands are theoretically known to
      be sparse in a weighted sense, and this manoever effectively perturbs the
      MCL process a little in order to obtain matrices that are genuinely
      sparse, thus keeping the computation tractable.  An example of monitoring
      pruning can be found in the discussion of \useopt{-v}{pruning} under the
      \optref{--verbose}{\genopt{--verbose} option}.

      \par
      \mcl proceeds as follows.
      First, entries that are smaller than \genarg{cutoff} are removed,
      resulting in a vector with at most \genarg{1/cutoff} entries.
      The cutoff can be supplied either by \genopt{-p}, or as the inverse value
      by \genopt{-P}. The latter is more intuitive, if your intuition is like
      mine (and the P stands for precision or pruning by the way).

      The cutoff just described is rigid; it is the same for all vectors.  The
      \optref{--adapt}{\genopt{--adapt} option} causes the computation of a
      cutoff that depends on a vector's homogeneity properties, and this option
      may speed up \mcl considerably.

      \par
      Second, if the remaining stochastic mass (i.e. the sum of all remaining
      entries) is less than \genarg{pct}/100 and the number of remaining
      entries is less than \genarg{r} (as specified by the \genopt{-R} flag),
      \mcl will try to regain ground by recovering the largest discarded
      entries. The total number of entries is not allowed to grow larger than
      \genarg{r}.

      If recovery was not necessary, \mcl tries to prune the vector further
      down to at most \genarg{s} entries (if applicable), as specified by the
      \genopt{-S} flag. If this results in a vector that satisfies the recovery
      condition then recovery is attempted, exactly as described above.
      The latter will not occur of course if \genarg{r} <= \genarg{s}.

      \par
      The default setting is something like \useopt{-P}{2000} \useopt{-S}{500}
      \useopt{-R}{600}.  Check the \genopt{-z} flag to be sure.  There is a set
      of precomposed settings, which can be triggered with the
      \optref{-scheme}{\genopt{-scheme}{k} option}. \genarg{k}=2 is the default
      scheme; higher values for \genarg{k} result in costlier and
      more accurate computations (vice versa for lower, cheaper, and less
      accurate).  The schemes are listed using the
      \genopt{--show-schemes} option. It is advisable to use the
      \genopt{-scheme} option only in interactive mode, and to use the explicit
      expressions when doing batch processing. The reason is that there
      is \it{no guarantee whatsoever} that the schemes will not change
      between different releases. This is because the scheme options
      should reflect good general purpose settings, and it may become
      appararent that other schemes are better.
      
      \par
      Note that 'less accurate' or 'more accurate' computations
      may still generate the same output clusterings. Use \clmdist
      to compare output clusterings for different resource parameters.
      Refer to \sib{clmdist} for a discussion of this issue.

      \par
      As a reminder of the existence of pruning and its importance for both
      speed and accuracy, \mcl reports three numbers when it is done, the
      'jury marks'.
      These are somewhat (but not totally) indicative for the quality of
      pruning, and they are excerpts from the output produced by
      \useopt{-v}{pruning}, namely the numbers listed under the \it{nx} column
      for the three first iterations. Each number gives the average stochastic
      mass  of the \usearg{nx} worst instances of pruning, i.e. those vectors
      for which the most mass was removed.  The average is listed as a
      percentage. The numbers should preferably be higher than 70.  If they are
      in the vicinity of 80 or 90, \mcl is doing fine as far as pruning is
      concerned.  Choose a higher scheme if you think them too low.
      For very dense graphs that do have strong cluster structure,
      the jury marks can sink as low as to the 30's
      and 40's, but the clusterings generated by \mcl may still be good.  
      Refer to the \optref{-v}{\genopt{-v} option} for more information, and
      note that the jury becomes friendlier, resp. harsher when the
      \genopt{-nx} option is increased/decreased.

\:    \par
\:    Judge the right settings for the parameters in this group by the time
\:    \mcl consumes and the quality of clusters it produces. Use
\:    \useopt{-v}{pruning} to see how much mass is kept on average. The average
\:    is computed over all matrix vectors, over the worst x instances, and the
\:    worst y instances (x and y are tunable using \genopt{-nx} and
\:    \genopt{-ny}).  Try to obtain parameter settings for which the overall
\:    average is always above 90% (mass kept), and for which the x and y
\:    averages quickly rise above 90% (see the discussion of
\:    \useopt{-v}{pruning} below the \optref{--verbose}{\genopt{--verbose}}
\:    option).
   \itemend

   \itemnew
   \item{\defopt{-warn-pct}{k}{prune warn percentage}}
   \item{\defopt{-warn-factor}{k}{prune warn factor}}
   \itemdef
      The two options \genopt{-warn-pct} and \genopt{-warn-factor} relate to
      warnings that may be triggered once the \it{initial} pruning of a vector
      is completed.  The idea is to issue warnings if initial pruning almost
      completely destroys a computed vector, as this may be a sign that the
      pruning parameters should be changed.  It depends on the mass remaining
      after initial pruning whether a warning will be issued.  If that mass is
      less than \it{warn-pct} or if the number of remaining entries is smaller
      by a factor \it{warn-factor} than both the number of entries originally
      computed \it{and} the recovery number, in that case, \mcl will issue a
      warning.

      \par
      \genopt{-warn-pct} takes an integer between 0 and 100 as parameter,
      \genopt{-warn-factor} takes a real positive number. They default to
      something like 30 and 50.0.  If you want to see less warnings, decrease
      \it{warn-pct} and increase \it{warn-factor}. Set \it{warn-factor} to zero
      if you want no warnings.
   \itemend

   \itemnew
   \item{\defopt{--rigid}{pruning}}
   \itemdef
      See the \genopt{--adapt} option below.
   \itemend

   \itemnew
   \item{\defopt{-ae}{f}{adaptive pruning exponent}}
   \itemdef
      See the \genopt{--adapt} option below.
   \itemend

   \itemnew
   \item{\defopt{-af}{f}{adaptive pruning factor}}
   \itemdef
      See the \genopt{--adapt} option below.
   \itemend

   \itemnew
   \item{\defopt{--adapt}{pruning}}
   \itemdef
      The default \mcl pruning behaviour as described under
      the \optref{-P}{\genopt{-P} option} is called \it{rigid pruning}
      (it being the default renders the switch \genopt{--rigid}
      currently useless), refering to the fact that the first stage
      of pruning removes entries smaller than a fixed threshold.
      The options discussed here enable the computation of a threshold that
      depends on the homogeneity characteristics of a vector. This behaviour is
      triggered by supplying \useopt{--adapt}.

      \par
      The \genopt{--adapt} behaviour only affects the first pruning stage, c.q.
      the computation of the first threshold (see the discussion under the
      \optref{-P}{\genopt{-P} option}).  It does not interfere with either
      selection or recovery.  It is affected however by the threshold as
      specified by the \genopt{-P} option.  When using \genopt{--adapt}, you
      typically use the \genopt{-P} option as well, and you can and should use
      a higher value then you would without using \genopt{--adapt}.

      \par
      All that said, \genopt{--adapt} triggers this behaviour: Given a
      stochastic vector v, its mass center of order two is computed,
      which is the sum of each entry squared. The mass center of v,
      call it c, is strongly related to its homogeneity properties
      (see \secref{references}).  The threshold T is computed as 1/f *
      pow(c, e), where e and f are the arguments to the \genopt{-af}{f}
      and \genopt{-ae}{e} options respectively (check \genopt{-z}
      for the respective defaults).
      For either e or f decreasing it means that T becomes larger.
      \it{Finally, T is maxed with the rigid threshold value}, which
      can be altered using either \genopt{-p}{f} or \genopt{-P}{n}.
      The latter is why you should increase the \genopt{-P} parameter n
      (so that the rigid threshold is decreased) once you switch to
      adaptive pruning. The adaptive threshold should be the main factor
      controlling pruning, with the rigid threshold acting as a safeguard
      that does not take over too often.

      \par
      This may seem complicated, but the rules are actually quite simple, and
      you may just disregard the definition of T.  The usefulness of these
      options will vary. If you want to speed up \mcl, try it out
      and add \useopt{--adapt} to your settings.
   \itemend

   \itemnew
   \item{\defopt{-nx}{x}{track worst n}}
   \itemdef
      See in the \genopt{--verbose} option below the discussion
      of the \it{pruning} mode.
   \itemend

   \itemnew
   \item{\defopt{-ny}{y}{track worst n}}
   \itemdef
      See in the \genopt{--verbose} option below the discussion
      of the \it{pruning} mode.
   \itemend

   \itemnew
   \item{\defopt{-v}{str}{verbosity type on}}
   \itemdef
      See the \genopt{--verbose} option below.
   \itemend

   \itemnew
   \item{\defopt{-V}{str}{verbosity type off}}
   \itemdef
      See the \genopt{--verbose} option below.
   \itemend

   \itemnew
   \item{\defopt{--silent}{very}}
   \itemdef
      See the \genopt{--verbose} option below.
   \itemend

   \itemnew
   \item{\defopt{--verbose}{very}}
   \itemdef
      These are the different verbosity modes:

      \par
      \bf{progress}\| 
      \bf{pruning}\| 
      \bf{explain}\| 
      \bf{all}

      \par
      where \it{all} means all three previous modes.
      \useopt{--verbose} and \useopt{-v}{all}
      turn them all on, \useopt{--silent} and \useopt{-V}{all}
      turn them all off. \genopt{-v}{str} and \genopt{-V}{str}
      turn on/off the single mode \genarg{str} (for \genarg{str}
      equal to one of \bf{progress}, \bf{pruning}, or \bf{explain}).
      Each verbosity mode is given its own entry below.
   \itemend

   \itemnew
   \item{\useopt{-v}{progress}}
   \itemdef
      This mode causes \mcl to emit an ascii gauge
      for each single matrix multiplication. It uses some
      default length for the gauge, which can be altered by
      the \genopt{-progress}{k} option. Simply using the latter
      will also turn on this verbosity mode.
      This mode can give you quickly an idea how long an \mcl
      run might take. If you use threading
      (see the \optref{-t}{\genopt{-t} option} and its friends),
      this option may slow down the program a little (relative to
      \useopt{-V}{progress}, not relative to a single-CPU \mcl run).
   \itemend

   \itemnew
   \item{\useopt{-v}{explain}}
   \itemdef
      This mode causes the output of explanatory headers illuminating the
      output generated with the \bf{pruning} verbosity mode.
   \itemend

   \itemnew
   \item{\useopt{-v}{pruning}}
   \itemdef
      The pruning process takes place during \it{expansion}, and is needed
      because expansion causes matrices to fill very rapidly. Expansion is
      nothing but taking the square of a stochastic matrix. The square is
      computed by successively computing its columns, which are stochastic
      vectors.  A new vector is first computed, and is then exposed to pruning.
      Pruning consists of either one or two out of \it{selection} and
      \it{recovery} \- see the discussion of \genopt{-S} and \genopt{-R} under
      the \optref{-P}{\genopt{-P} option}.

      \par
      Pruning verbosity mode causes \mcl to emit several statistics related to
      the pruning process, each of which is described below.  Use
      \useopt{-v}{explain} to get explanatory headers in the output as well.

      \par{Selection and recovery}
      The number of selections and recoveries \mcl had to perform during each
      iteration is shown.  It also shows the number of vectors for which the
      mass after final pruning was below the fraction defined by the
      \optref{-pct}{\genopt{-pct} option} as a percentage (default probably 90
      or 95).

      \par{Initial and final vector footprint distributions}
      The distribution of the vector footprints (i.e. the number of nonzero
      entries) before and after pruning is shown. This is assembled in a terse
      (horrid if you will) ascii output format, looking as follows
      (with some context stripped, noting that the data for three
      multiplications is shown):

\begin{vbtbl}
----------------------------------------------------
 mass percentages  | distribution of vec footprints|
         |         |__ compose ________ prune _____|
  prune  | final   |000  00   0    |000  00   0    |
all ny nx|all ny nx|8532c8532c8532c|8532c8532c8532c|
---------.---------.---------------.---------------.
 98 88 86  98 91 86 ____0224567899@ ______02346899@ 
 98 89 86  98 94 91 __002456789@@@@ ______02346899@ 
 98 90 89  99 95 94 __002355689@@@@ ______02346789@ 
 ...
\end{vbtbl}

      \par
      This particular output was generated (and truncated after three rounds
      of expansion and inflation) from clustering
      a protein graph on 9058 nodes with settings \useopt{-I}{1.4},
      \useopt{-P}{2000}, \useopt{-S}{500}, \useopt{-R}{600},
      and \useopt{-pct}{95} (which was supplied more succinctly
      as \useopt{-scheme}{2} \useopt{-pct}{95}).

      \par
      The header entries 8532c85.. with the zeroes on top indicate
      thresholds going from 8000, 5000, 2000, 1250, 800, all the way down
      to 30, 20, and 12. The character 'c' signifies the base 12.5 (for
      no apparent reason). The
      second entry '2' (after '0') signifies that roughly 20 percent
      of all the vectors had footprint (#nonzero entries) between 800 and
      1250. Likewise, 80 percent had footprint between 500 and 800. The '0'
      entries signify a fraction somewhere below 5 percent, and the '@'
      entries signify a fraction somewhere above 95 percent.

      \par
      Two columns are listed, one for the composed vector footprints
      (i.e. after squaring), and the other for the vector
      footprints \it{right after initial pruning took place} (i.e. before
      selection and recovery, after either adaptive or rigid pruning).
      This may give an idea of the soundness of the initial  pruning
      process (overly severe, or overly mild), and the extent
      to which you want to apply selection and/or recovery.

      \par{Initial and final vector mass distributions}
      The mass averages of the pruned vectors after the first selection
      stage are shown, and the mass averages of the vectors as \it{finally
      pruned}, i.e. after selection and recovery.  Note that the latter
      corresponds to a different stage than what is shown for the vector
      footprints, if either selection or recovery is turned on.

      The mass averages are shown as percentages: '88' means that overall
      88 percent of the stochastic mass of the matrix was kept.  For both
      cases, three averages are shown: the average of all vectors,
      the average of the worst x cases, and the average of the worst y
      cases. The values x and y default to something like x=10 and y=100;
      check the \optref{-z}{\genopt{-z} option} to be sure. They can be
      changed using \useopt{-nx}{x} and \useopt{-ny}{y}.
      The jury marks refered to earlier are in this particular case [86,91,94].

      \par
      In the example above it is clearly seen that many entries could be
      removed while retaining much of the stochastic mass. The effect of the
      recovery (\genopt{-R}) parameter is also clear: the final averages are
      higher than the initial averages, as a result of  \mcl undoing some
      overenthousiastic pruning.
   \itemend

   \itemnew
   \item{\defopt{-progress}{k}{gauge}}
   \itemdef
      If k>0 then for each matrix multiplication \mcl will print an
      ascii gauge telling how far it is. The gauge will be (in some
      cases approximately) k characters long. If k<0 then \mcl will
      emit a gauge that is extended by one character after every |k|
      vectors computed. For large graphs, this option has been known
      to ease the pain of impatience. If k=0 then \mcl will print a
      message only after every matrix multiplication, and not during
      matrix multiplication. This can be useful when you want \mcl to be
      as speedy as possible, for example when using parallellized mode
      (as monitoring progress requires thread communication).
      For parallellization (by threading) see the
      \optref{-t}{\genopt{-t} option}.
   \itemend

   \itemnew
   \item{\defopt{-te}{k}{#expansion threads}}
   \itemdef
      See the \genopt{-t}{k} option below.
   \itemend

   \itemnew
   \item{\defopt{-ti}{k}{#inflation threads}}
   \itemdef
      See the \genopt{-t}{k} option below.
   \itemend

   \itemnew
   \item{\defopt{--clone}{when threading}}
   \itemdef
      See the \genopt{-t}{k} option below.
   \itemend

   \itemnew
   \item{\defopt{-cloneat}{n}{trigger}}
   \itemdef
      See the \genopt{-t}{k} option below.
   \itemend

   \itemnew
   \item{\defopt{-t}{k}{#threads}}
   \itemdef
      The \genopt{-t} options are self-explanatory.  Note that threading
      inflation is hardly useful, as inflation is orders of magnitude
      faster than expansion.  Also note that threading is only useful
      if you have a multi-processor system.
      
      \par
      The \genopt{--clone}
      option says to give each thread its own copy of the matrix being
      expanded/squared.  The latter option can be further controlled
      using the \genopt{--cloneat}{k} option. Copies are only made if
      the source matrix (the one to be squared) has on average at least
      k positive entries per vector.

      \par
      When threading, it is best not to turn on pruning verbosity
      mode if you are letting mcl run unattended, unless you want to
      scrutinize its output later. This is because it makes \mcl run
      somewhat slower, although the difference is not dramatic.
   \itemend

   \itemnew
   \item{\defopt{-l}{n}{initial iteration number} (small letter ell)}
   \itemdef
      The number of times \mcl will use a different inflation value
      before it switches to the (main) inflation given by the \genopt{-I}
      (capital eye) option. The different value is called \it{initial
      inflation} and is tunable using the \optref{-i}{\genopt{-i}{f}
      option} (default value f=2.0).  The default value (to \genopt{-l})
      is zero.  This option supplies new ways of affecting cluster
      granularity, e.g. by supplying

\begin{vbt}
   mcl proteins -i 1.4 -l 2 -I 4.0
\end{vbt}

      \par
      one lets expansion prevail during the first two iterations,
      followed by inflation catching up (in a figurative way of writing).
      This may be useful in certain cases, but this type of experiment
      is \it{certainly secondary} to simply varying \genopt{-I} (capital eye).
   \itemend

   \itemnew
   \item{\defopt{-L}{n}{main iteration number}}
   \itemdef
      Normally, \mcl computes the MCL process until it has converged
      fully to a doubly idempotent matrix. The number of iterations
      required is typically somewhere in the range 10-100.
      The first few iterations generally take the longest time.
      The \genopt{-L} option can be used to specify the number of
      iterations \mcl may do at most. When this number is reached,
      \mcl will output the clustering associated with the iterand
      last computed.
   \itemend

   \itemnew
   \item{\defopt{-i}{f}{initial inflation}}
   \itemdef
      The inflation value used during the first n iterations,
      where n is specified by the \genopt{-l} (ell) option.
      By default, n=0 and f=2.0.
   \itemend

   \itemnew
   \item{\defopt{-a}{f}{loop weight}}
   \itemdef
      \bf{Deprecated}\~\~Like the \optref{-c}{\genopt{-c} option},
      except that it adds loops of absolute weight.  This can be intuitive
      when testing with simple graphs, however, using \useopt{-c}{f}
      will in this case have exactly the same effect as \useopt{-a}{f},
      so do use the former.
   \itemend

   \itemnew
   \item{\defopt{-dumpi}{i:j}{interval i..j-1}}
   \itemdef
      Dump during iterations i..j-1. See the \genopt{-dump}{str} option below.
   \itemend

   \itemnew
   \item{\defopt{-dumpm}{k}{dump i+0..i+k..}}
   \itemdef
      Sampling rate: select only these iterations in the dump interval.
      See the \genopt{-dump}{str} option below.
   \itemend

   \itemnew
   \item{\defopt{-dumpstem}{stem}{file stem}}
   \itemdef
      Set the the stem for file names of dumped
      objects (default \it{mcl}). See the \genopt{-dump}{str} option below.
   \itemend

   \itemnew
   \item{\defopt{-dump}{str}{type}}
   \itemdef
      \genarg{str} can be of the following types.

      \par
      \bf{att}\| 
      \bf{ite}\| 
      \bf{cls}

      \par
      Repeated use is allowed. The \bf{att} option says to output a vector
      measuring for each node how much it is attracted to itself (which
      measures the extent to which nodes are situated in the core of a
      cluster).  It is somewhat forlorn because the other mcl utilities
      (see the \secref{seealso} section) can not yet utilize its output.
      The \bf{ite} option writes \mcl iterands to file.  The \bf{cls}
      option writes clusterings associated with \mcl iterands to file.

      \par
      The \genopt{-dumpstem} sets the stem for file names of dumped
      objects (default \it{mcl}).  The \genopt{-dumpi} and \genopt{-dumpm}
      allow a selection of iterands to be made.
   \itemend

   \itemnew
   \item{\defopt{-digits}{n}{printing precision}}
   \itemdef
      See the \optref{--show}{\genopt{--show} option} below.
   \itemend

   \itemnew
   \item{\defopt{--show}{print matrices to screen}}
   \itemdef
      Print matrices to screen. The number of significant digits to be
      printed can be tuned with \genopt{-digits}{n}. An 80-column screen
      allows graphs (matrices) of size up to 12(x12) to be printed with
      three digits precision (behind the comma), and of size up to 14(x14)
      with two digits. This can give you an idea of how \mcl operates,
      and what the effect of pruning is. Use e.g. \useopt{-S}{6} for such
      a small graph and view the MCL matrix iterands with \genopt{--show}.
   \itemend

   \itemnew
   \item{\defopt{--ascii}{output format}}
   \itemdef
      See the \optref{--binary}{\genopt{--binary} option} below.
   \itemend

   \itemnew
   \item{\defopt{--binary}{output format}}
   \itemdef
      Write the resulting clustering in binary mcl format rather
      than ascii mcl format (the default). Note that \mcxconvert
      can be used to convert each one into the other.
      See \mcx5ref and \sib{mcxconvert} for more information.
   \itemend

   \itemnew
   \item{\defopt{--overlap}{keep it}}
   \itemdef
      Keep overlap. In theory, \mcl may generate a clustering that
      contains overlap, although this almost never happens in practice,
      as it requires some particular type of symmetry to be present in
      the input graph (not just any symmetry will do).  Mathematically
      speaking, this is a conjecture and not a theorem, but I am willing
      to eat my shoe if it does not hold (for marzipan values
      of shoe).  It is easy though to construct an input graph for which
      certain \mcl settings result in overlap - for example a line graph
      on an odd number of nodes.  The default is to remove overlap should
      it occur.

      \par
      This option has more than theoretical use because \mcl is able
      to generate clusterings associated with intermediate iterands.
      For these clusterings, overlap is more than a theoretical
      possibility, and will often occur. If you specify
      the \optref{-L}{\genopt{-L}{k}} option, \mcl will output the
      clustering associated with the last iterand computed, and
      it may well contain overlap.

      \par
      This option has no effect on the clusterings that are
      output when using \optref{-dump}{\genopt{-dump}{cls}} -
      the default for those is that overlap is not touched,
      and this default can not yet be overridden.
   \itemend

   \itemnew
   \item{\defopt{--inflate-first}{rather then expand}}
   \itemdef
      Normally, \mcl will take the input graph/matrix, make it stochastic, and
      start computing an \mcl process, where expansion and inflation are
      alternated.  This option changes that to alternation of inflation and
      expansion, i.e. inflation is the first operator to be applied.  This is
      intended for use with an input matrix that was generated with the
      \genopt{--expand-only} option (see below).

      If you do multiple \mcl runs for the same graph, then the first step will
      be the same for all runs, namely computing the square of the input
      matrix.  With the pair of \genopt{--inflate-first} and
      \genopt{--expand-only} this bit of computing can be factored out.

      \bf{NOTE} this option assumes that the input matrix is stochastic
      (as it will be when generated with \genopt{--expand-only}.
      
      The \genopt{--inflate-first} option renders all options useless that will
      otherwise affect the input matrix, and precisely these options \it{do}
      affect the matrix resulting from using \genopt{--expand-only}. See the
      entry below for more information.
   \itemend

   \itemnew
   \item{\defopt{--expand-only}{factor out computation}}
   \itemdef
      This option makes \mcl compute just the square of the input graph/matrix,
      and write it to the file name supplied with the \genopt{-o} flag, or to
      the default file named out.mce.  \bf{NOTE} in this case the output matrix
      is \it{not} a clustering.  The intended use is that the output matrix is
      used as input for \mcl with the \genopt{--inflate-first} switch turned
      on, so that multiple \mcl runs need not redo the same computation (the
      first expansion step).
      
      \par
      Note that the \optref{-scheme}{\genopt{-scheme} parameters} affect the
      matrix computed with \genopt{--expand-only}.  Other options that affect
      the matrix resulting from this option:
      \optref{-preprune}{\genopt{-preprune}}, \optref{-c}{\genopt{-c}},
      and \optref{-digits}{\genopt{-digits}}. The latter option
      sets the precision for output in native ascii format.
      This is overloading the \genopt{-digits} option, as it has a different
      meaning if \genopt{--expand-only} is not supplied.
   \itemend

   \itemnew
   \item{\defopt{-preprune}{n}{input matrix}}
   \itemdef
      For each column vector (node) in the input matrix (graph) \mcl will 
      keep the n entries (outgoing edges) of that vector (node) that
      have largest weight and remove the rest.
   \itemend

   \itemnew
   \item{\defopt{-z}{show settings}}
   \itemdef
      Show current settings for tunable parameters.
      \genopt{--show-settings} is a synonym.
   \itemend

   \itemnew
   \item{\bf{That's All Folks}}
   \itemdef
      for now.
   \itemend
\end{itemize}

\sec{applicability}{APPLICABILITY}
\par
   \mcl will work very well for graphs in which the diameter of the natural
   clusters is not too large. The presence of many edges between different
   clusters is not problematic; as long as there is cluster structure, \mcl
   will find it.  It is less likely to work well for graphs with clusters
   (inducing subgraphs) of large diameter, e.g.  grid-like graphs derived from
   Euclidean data. So \mcl in its canonical form is certainly not fit for
   boundary detection or image segmentation. I experimented with a modified
   \mcl and image segmentation in the thesis pointed to below (see
   \secref{references}).  This was fun and not entirely unsuccesful, but not
   something to be pursued further.

\par
   \mcl likes \it{undirected input graphs best}, and it really dislikes graphs
   with node pairs (i,j) for which an arc going from i to j  is present and the
   counter-arc from j to i is absent.  Try to make your input graph undirected.
   Furthermore, \mcl interprets edge weights in graphs as similarities.  If you
   are used to working with dissimilarities, you will have to convert those to
   similarities using some conversion formula.  The most important thing is
   that you feel confident that the similarities are reasonable, i.e. if X is
   similar to Y with weight 2, and X is similar to Z with weight 200, then this
   should mean that the similarity of Y (to X) is neglectible compared with the
   similarity of Z (to X).

\par
   \mcl is probably not suited for clustering \it{tree graphs}. This is because
   mcl works best if there are multiple paths between different nodes in the
   natural clusters, but in tree graphs there is only one path between any pair
   of nodes. Trees are too sparse a structure for \mcl to work on.

\par
   \mcl may well be suited for clustering \it{lattices}. It will depend
   on the density characteristics of the lattice, and the conditions for
   success are the same as those for clustering graphs in general: The
   diameter of the natural clusters should not be too large.
   \bf{NOTE} when clustering a lattice, you \it{have} to cluster
   the underlying undirected graph, and not the directed graph that represents
   the lattice itself.  The reason is that one has to allow \mcl (or any other
   cluster algorithm) to 'look back in time', so to speak.  Clustering and
   directionality bite each other (long discussion omitted).

\par
   \mcl has a worst-case time complexity O(N*k^2), where N is the number of
   nodes in the graph, and k is the maximum number of neighbours tracked during
   computations. k depends on the \genopt{-P} and \genopt{-S} options.  If the
   \genopt{-S} option is used (which is the default setting) then k equals the
   value corresponding with this option. Typical values for k are in the range
   500..1000. The average case is much better than the worst case though, as
   cluster structure itself has the effect of helping \mcl's pruning schemes,
   certainly if the diameter of natural clusters is not large.

\sec{files}{FILES}
\par
   There are currently no resource nor configuration files.
   The mcl matrix format is described in the \mcx5ref section.

\sec{environment}{ENVIRONMENT}
\par
   Currently, no environmental issues with \mcl.

\sec{diagnostics}{DIAGNOSTICS}
\par
   If \mcl issues a diagnostic error, it will most likely be
   because the input matrix could not be parsed succesfully.
   \mcl tries to be helpful in describing the kind of parse error.
   The mcl matrix format is described in the \mcx5ref section.

\sec{bugs}{BUGS}
\par
   No known bugs at this time. Please send bug reports to mcl-bugs@mdcc.cx.

\sec{author}{AUTHOR}
\par
   Stijn van Dongen.

\sec{history}{HISTORY/CREDITS}
\par
   The MCL algorithm was conceived in spring 1996 by the present author.
   The first implementation of the MCL algorithm followed that spring
   and summer. It was written in Perl and proved the viability of
   the algorithm. The implementation described here began its life in
   autumn 1997. The first versions of the vital matrix library
   were designed jointly by Stijn van Dongen and Annius Groenink in
   the period Oktober 1997 - May 1999. The efficient matrix-vector
   multiplication routine was written by Annius. This routine is
   without significant changes still one of the cornerstones of this
   MCL implementation.

\par
   Since May 1999 all MCL libraries have seen much development and
   redesign by the present author. Matrix-matrix multiplication has been
   rewritten several times to take full advantage of the sparseness
   properties of the stochastic matrices brought forth by the MCL
   algorithm. This mostly concerns the issue of pruning \- removal of
   small elements in a stochastic column in order to keep  matrices
   sparse.

\par
   Very instructive was  that around April 2001 Rob  Koopman pointed out
   that selecting  the k largest  elements out of  a collection of  n is
   best done  using a  min-heap. This  was the key  to the  second major
   rewrite (now counting three) of the MCL pruning schemes, resulting in
   much faster code, generally producing  a more accurate computation of
   the MCL process.

\par
   In May 2001  Anton Enright initiated the parallellization  of the
   \mcl code and threaded inflation. From this example, Stijn threaded
   expansion.  This was great, as the MCL data structures  and operands
   (normal matrix multiplication and Hadamard multiplication) just beg
   for parallellization.

\par
   Joost van Baal set up the \mcl CVS tree and packaged \mcl for Debian
   GNU/Linux. He completely autotooled the sources, so much so that at first I
   found it hard to find them back amidst bootstrap, aclocal.m4, depcomp, and
   other beauties.

\par
   Jan van der Steen shared his elegant mempool code. Philip Lijnzaad
   and Shawn Hoon sent useful bug reports.

\sec{seealso}{SEE ALSO}

\par
   \mcl development is discussed on \vbt{mcl-devel@lists.mdcc.cx}, this list is
   archived at \httpref{http://lists.mdcc.cx/mcl-devel/}.

\par
   \mcx5ref - a description of the mcl matrix format.

\par
   \sib{mcx} - an interpreter for a stack language that enables
   interaction with the \mcl matrix libraries.  It can be used both from the
   command line and interactively, and supports a rich set of operations such
   as transposition, scaling, column scaling, multiplication, Hadamard powers
   and products, et cetera. The general aim is to provide handles for simple
   number and matrix arithmetic,
   and for graph, set, and clustering operations.  The following is
   a very simple example of implementing and using \mcl in this language.

\begin{vbt}
 2.0 .i def                    # define inflation value.
 /small lm                     # load matrix in file 'small'.
 dim id add                    # add identity matrix.
 st .x def                     # make stochastic, bind to x.
 { xpn .i infl vm } .mcl def   # define one mcl iteration.
 20 .x .mcl repeat             # iterate  20 times
 imac                          # interpret matrix as clustering.
 vm                            # view matrix (clustering).
\end{vbt}

\par
   One of the more interesting things that can be done is doing mcl runs
   with more complicated inflation profiles than the two-constant approach used
   in \mcl itself.

\par
   Several other utilities come with \mcl, facilitating analysis and
   comparison of different clusterings.

\par
   \sib{clmdist} - compute the split/join distance between two 
   partitions. The split/join distance is better suited for measuring partition
   similarity than the long-known equivalence mismatch coefficient. The former
   measures the number of node moves required to transform one partition into
   the other, the latter measures differences between volumes of edges of
   unions of complete graphs associated with partitions.

\par
   \sib{clminfo} - compute a performance measure saying how well
   a clustering captures the edge weights of the input graph. Useful
   for comparing different clusterings on the same graph, best used in
   conjunction with \clmdist - because comparing clusterings at
   different levels of granularity should somewhat change the performance
   interpretation. The latter issue is discussed in the \sib{clmdist}
   entry.

\par
   \sib{clmmeet} - compute the intersection of a set of clusterings,
   i.e. the largest clustering that is a subclustering of all. Useful
   for measuring the consistency of a set of different clusterings
   at supposedly different levels of granularity (in conjunction with
   \clmdist).

\par
   \sib{clmconf} - for inspecting local cluster structure.
   Computes how well nodes fit into the cluster
   in which they are located (for a given clustering) by looking at
   the (weighted) percentage of its edges going to that same cluster.
   Computes also the cohesiveness of a cluster, by computing and averaging
   the above over all nodes in a cluster.  Useful for inspecting local
   cluster structure.

\par
   \sib{mcxsubs} - compute a submatrix of a given matrix, where row
   and column index sets can be specified as lists of indices combined
   with list of clusters in a given clustering. Useful for inspecting
   local cluster structure.

\par
   \sib{mcxconvert} - convert matrices from ascii mcl format to
   binary mcl format or vice versa.

\sec{references}{REFERENCES}

\par
   \bf{Graph Clustering by Flow Simulation} (thesis)\|
   \httpref{http://www.library.uu.nl/digiarchief/dip/diss/1895620/inhoud.htm}

\par
   \bf{A cluster algorithm for graphs} (technical report)\|
   \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0010.ps.Z}

\par
   \bf{A stochastic uncoupling process for graphs} (technical report)\|
   \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0011.ps.Z}

\par
   \bf{Performance criteria for graph clustering and
         Markov cluster experiments} (technical report)\|
   \httpref{http://www.cwi.nl/ftp/CWIreports/INS/INS-R0012.ps.Z}

\par
   \bf{An efficient algorithm for large-scale detection of protein families}
         (preprint)\|
   Not yet available.

\sec{notes}{NOTES}

\par
   This page was generated from \bf{ZOEM} manual macros.
   Both html and roff pages can be created from the same source without having
   to bother with all the usual conversion problems, while keeping some level
   of sophistication in the typesetting. The ZOEM primitives only provide macro
   expansion and filter capabilities; the proof of the typesetting is in
   striking the macros right.

\"man::postamble"

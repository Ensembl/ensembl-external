#!/bin/sh

hdr_stats="PRUNING STATISTICS"
hdr_pruning="PRUNING REGIMES"
hdr_credits="CREDITS"

str_SECTION="MCL (Markov Cluster Algorithm)"
hdr_SECTION="                                                $str_SECTION"


ctt_credits=$(cat <<__lines__
$hdr_SECTION
                     $hdr_credits

   The  first versions  of  the vital  matrix  library (currently  named
   nonema for NOn NEgative MAtrices, but  this name will not stick) were
   designed  jointly by  Stijn van  Dongen  and Annius  Groenink in  the
   period  Oktober 1997  - May  1999. Its  data structures  were largely
   derived from an  earlier (1996) prototype MCL  implementation in Perl
   --  although it  is  not  as if  the  abstract  MCL algorithm  leaves
   much  room  for  variation  here.  During that  period  I  learned  a
   great deal  about C coding  from Annius. The  efficient matrix-vector
   multiplication  routine was  written by  Annius. He  contributed many
   other lines of code, but  this routine is without significant changes
   still one of the cornerstones of this MCL implementation.

   Since  May 1999  all MCL  libraries  have seen  much development  and
   redesign  by  yours  truly.  Matrix-matrix  multiplication  has  been
   rewritten  several times  to take  full advantage  of the  sparseness
   properties  of  the stochastic  matrices  brought  forth by  the  MCL
   algorithm. This  mostly concerns the  issue of pruning --  removal of
   small  elements in  a stochastic  column  in order  to keep  matrices
   sparse.

   Very instructive was  that around April 2001 Rob  Koopman pointed out
   that selecting  the k largest  elements out of  a collection of  n is
   best done  using a  min-heap. This  was the key  to the  second major
   rewrite (now counting three) of the MCL pruning schemes, resulting in
   much faster code, generally producing  a more accurate computation of
   the MCL process.

   In May 2001  Anton Enright initiated the parallellization  of the MCL
   code and did a  large part of the pthread coding.  This was great, as
   the MCL  data structures  and operands (normal  matrix multiplication
   and Hadamard multiplication) just beg for parallellization.

                                                              Stijn van Dongen
__lines__
)


ctt_stats=$(cat <<__lines__
$hdr_SECTION
                     $hdr_stats

   Note: in the  context of the MCL algorithm, 'vector  size' means 'the
   number  of positive  entries' [of  that  vector], and  an 'entry'  or
   'vector entry' is a *positive* vector entry.

   In the output resulting from the '-v pruning' option, two columns are
   headed by  the tag 8532c8532c8532c.  Each instance heads  15 columns.
   The columns  correspond with cardinalities, namely  8,000 5,000 3,000
   2,000 1,250 800 500  all the way down to 30 20  and 12. The character
   'c' was  chosen to  represent the  number 1.25  for no  clear reason.
   Below each  column you  find rounded fractions.  A fraction  is taken
   relative to the number 10 and denoted  by the integers 0-9 and the at
   sign '@'. '0' signifies the range 0-5%, '1' signifies the range 5-15%
   ...  and '@'  signifies  the range  95-100%.  Fractions indicate  the
   number of  vectors for which  the composed resp pruned  size exceeded
   the cardinality corresponding with that column (relative to the total
   number  of  vectors).  The  two  row  entries  thus  represent  rough
   estimates of  the distributions of  vector sizes of  respectively the
   vectors as they are first computed during expansion (matrix squaring)
   and the vectors after being exposed to (automatic) threshold pruning.
   This  information  might be  useful  in  tuning the  pruning  process
   (mainly the -p, -m, and --adapt flags), and it looks cute too.

__lines__
)

ctt_pruning=$(cat <<__lines__
$hdr_SECTION
                     $hdr_pruning

   Note: in the  context of the MCL algorithm, 'vector  size' means 'the
   number  of positive  entries' [of  that  vector], and  an 'entry'  or
   'vector entry' is a *positive* vector entry.

   Pruning means removing the smallest  entries in a matrix column after
   expansion.  This  is  done  in  order  to  keep  MCL  computationally
   tractable, as it keeps matrices sparse (matrices that are sparse in a
   weighted sense  in the  first place).  The column  is rescaled  to be
   stochastic  afterwards, and  ideally  removal of  a  fraction of  the
   stochastic mass leads to a drastic decrease of the number of positive
   entries. This is in fact most often  the case. Do '-v pruning' to see
   how well MCL is doing in this respect.

   There are  two major MCL  pruning modes, resp 'adaptive'  and 'rigid'
   pruning.  The argument  M  to the  -m  or -M  flag  causes a  further
   branching in modes;  it matters whether this value is  zero (which is
   the default) or  positive. The options --recover and  --select play a
   role here too.

   <> Rigid mode

   In rigid mode  all entries smaller than a fixed  threshold T given by
   the -p flag (memnonic: precision) are removed. A natural way to think
   of the  T value is that  after thresholding with this  value a column
   will never have  more than 1/T entries (this is  more an afterthought
   than  a rationale  though). Typical  values T  for lie  in the  range
   1/1000 .. 1/N where N is the  cardinality of the graph. It is in fact
   possible to  specify p via its  reciprocal using the -P  flag: -P <i>
   will set T to  the value 1/i. For speed it is  advisable to assign to
   the  -P flag  a  value roughly  equal  to  4 or  5  the average  node
   degree,  perhaps  somewhat  less  or more  depending  on  your  graph
   connectivity and  available computing resources.  The default is  T =
   1e-3, corresponding with a P value 1000.

   <> Adaptive mode

   In adaptive mode, a second threshold is computed which depends on the
   columns homogeneity properties.  This threshold is maxed  with the -p
   value  T,  and the  resulting  threshold  is  applied to  the  column
   entries. This threshold equals [ center * 1/f * pow(center/maxval, e)
   ], where f and e equal  the -af resp -ae arguments. [more information
   on center and maxval should go here]

   <> The mark number

   In both rigid and adaptive mode, a mark number M can be specified via
   either the -m  or -M flag. If  M is specified, it may  trigger one of
   two actions for any given column. The two actions are

      o Selection

      A column with more than M entries is further pruned until it has M
      entries (approximately M entries in  case of ties). For very dense
      graphs it can be useful to do  selection by specifying M as it may
      be  difficult to  tune pruning  by thresholds  only. Selection  is
      activated by either supplying both  -m <i> and --select (then M=i)
      or by  supplying -M <i>, which  is equivalent to '-m  <i> --select
      --recover'.

      o Recovery

      If M  is specified, and  if threshold  pruning leaves less  than M
      entries and less mass than the fraction F, where F is specified as
      a percentage with  the -pct flag (default value 95),  MCL tries to
      remedy the situation by recovering  as much mass as possible given
      the bound of M entries. This  behaviour is activated by the option
      --recover in  conjunction with -m  <i> or in  case you use  -M <i>
      (which activates  both selection and recovery).  Recovery may undo
      overenthousiastic pruning within the entry bound set by M.

      o Supplying -m <i> only

      If -m <i>  is specified neither with --select  nor with --recover,
      MCL will  only tell you the  number of cases where  it should have
      applied selection and  where it should have  applied recovery, but
      it will  not actually do either  of them. The counts  are shown if
      you supply the -v pruning option.  Note that the counts shown with
      -m <i>  (only) and -M <i>  are generally not identical,  as actual
      selection and recovery affects the counts at later stages.

__lines__
)

case "$1" in 
   "8532c")
      less <<__MCL__

$ctt_stats

__MCL__
;;


   "credits")
      less <<__MCL__

$ctt_credits

__MCL__
;;


   "pruning")
      less <<__MCL__

$ctt_pruning

__MCL__
;;


   "all")
      less <<__MCL__

$ctt_pruning


$ctt_stats


$ctt_credits

__MCL__
;;


   *)
      cat <<__MCL__

   mcldoc argument      Section

   pruning              $hdr_pruning
   stats                $hdr_stats
   credits              $hdr_credits
   all                  all sections joined together

__MCL__
;;

esac

